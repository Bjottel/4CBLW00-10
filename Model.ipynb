{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0468c0dc-59dc-40f5-b36c-60d60235bc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20234238\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "CSV_PATH = 'spectra.csv'\n",
    "\n",
    "# Index -> functional group name\n",
    "label_map = [\n",
    "    'phenol',\n",
    "    'aldehyde',\n",
    "    'arene'\n",
    "]\n",
    "num_classes = len(label_map)\n",
    "\n",
    "# Torch expects every label list to have the same length. Not all samples have the same amount of labels, so instead\n",
    "# we convert the labels to a multi hot vector v, where v_i = 1 if the sample has label i and v_i = 0 otherwise\n",
    "def labels_to_multi_hot_vector(labels):\n",
    "    multi_hot_vector = []\n",
    "    for i in range(len(label_map)):\n",
    "        if label_map[i] in labels:\n",
    "            multi_hot_vector.append(1)\n",
    "        else:\n",
    "            multi_hot_vector.append(0)\n",
    "    return torch.tensor(multi_hot_vector, dtype=torch.float32)\n",
    "\n",
    "class IRDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None, target_transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        # Parse all the json encoded spectra\n",
    "        self.df['spectrum'] = self.df['spectrum'].apply(json.loads)\n",
    "        # Convert the string labels to a multi hot vector\n",
    "        self.df['labels'] = self.df['labels'].apply(labels_to_multi_hot_vector)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        spectrum = self.df['spectrum'].iloc[idx]\n",
    "        # Torch expects spectra as a tensor, not a list\n",
    "        spectrum = torch.tensor(spectrum, dtype=torch.float32)\n",
    "        \n",
    "        labels = self.df['labels'].iloc[idx]\n",
    "        \n",
    "        if (self.transform):\n",
    "            spectrum = self.transform(spectrum)\n",
    "        if (self.target_transform):\n",
    "            labels = self.target_transform(labels)\n",
    "        return spectrum, labels    \n",
    "    \n",
    "dataset = IRDataset(CSV_PATH)\n",
    "\n",
    "# TODO: make this split more fair by ensuring groups are evenly split between train/test\n",
    "# (also add validation set?)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78cf0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(predictions, true_labels, label_index):\n",
    "    true_positive = sum((predictions[i][label_index] == 1).item() and (true_labels[i][label_index] == 1).item() for i in range(len(predictions)))\n",
    "    false_positive = sum((predictions[i][label_index] == 1).item() and (true_labels[i][label_index] == 0).item() for i in range(len(predictions)))\n",
    "    if true_positive == 0:\n",
    "        return 0.0\n",
    "    return true_positive / (true_positive + false_positive)\n",
    "\n",
    "def recall(predictions, true_labels, label_index):\n",
    "    true_positive = sum((predictions[i][label_index] == 1).item() and (true_labels[i][label_index] == 1).item() for i in range(len(predictions)))\n",
    "    false_negative = sum((predictions[i][label_index] == 0).item() and (true_labels[i][label_index] == 1).item() for i in range(len(predictions)))\n",
    "    if true_positive == 0:\n",
    "        return 0.0\n",
    "    return true_positive / (true_positive + false_negative)\n",
    "    \n",
    "def f1_score(predictions, true_labels, label_index):\n",
    "    precision_score = precision(predictions, true_labels, label_index)\n",
    "    recall_score = recall(predictions, true_labels, label_index)\n",
    "    if precision_score == 0 and recall_score == 0:\n",
    "        return 0.0\n",
    "    return 2 * precision_score * recall_score / (precision_score + recall_score)\n",
    "\n",
    "def EMR(predictions, true_labels):\n",
    "    return (predictions == true_labels).all(axis=1).mean()\n",
    "                \n",
    "def evaluate(model, data_loader, batch_transform, device = 'cpu'):\n",
    "    model.eval()\n",
    "    \n",
    "    all_true_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch_inputs, batch_labels in data_loader:\n",
    "            batch_inputs = batch_transform(batch_inputs).to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            outputs = model(batch_inputs)\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predictions = (probabilities > 0.5).float()\n",
    "        \n",
    "            all_true_labels.append(batch_labels)\n",
    "            all_predictions.append(predictions)\n",
    "    \n",
    "    y_true = torch.cat(all_true_labels).cpu().numpy()\n",
    "    y_pred = torch.cat(all_predictions).cpu().numpy()\n",
    "\n",
    "    results = {}\n",
    "    f1_scores = []\n",
    "    for i in range(len(label_map)):\n",
    "        results[label_map[i]] = {}\n",
    "        results[label_map[i]]['precision'] = precision(y_pred, y_true, i)\n",
    "        results[label_map[i]]['recall'] = recall(y_pred, y_true, i)\n",
    "        f1 = f1_score(y_pred, y_true, i)\n",
    "        results[label_map[i]]['f1_score'] = f1\n",
    "        f1_scores.append(f1)\n",
    "    results['macro'] = {}\n",
    "    results['macro']['f1_score'] = np.mean(f1_scores)\n",
    "    results['macro']['EMR'] = EMR(y_pred, y_true)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c43f57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 12:48:07,817] A new study created in memory with name: no-name-2873b877-7d9e-4acb-82a2-c1620c22143e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Using cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-06-04 12:48:09,874] Trial 0 failed with parameters: {'learning_rate': 0.00024884398041942127, 'conv_layers': 2, 'conv0_outchannels': 32, 'conv0_kernelsize': 11, 'conv1_outchannels': 32, 'conv1_kernelsize': 5, 'fc_layers': 3, 'fc0_size': 512, 'dropout0': 0.20286414651558832, 'fc1_size': 128, 'dropout1': 0.1711371185900922, 'fc2_size': 512, 'dropout2': 0.09787127195927298} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\20234238\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\20234238\\AppData\\Local\\Temp\\ipykernel_21232\\1854491737.py\", line 87, in objective\n",
      "    loss.backward()\n",
      "  File \"C:\\Users\\20234238\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\_tensor.py\", line 489, in backward\n",
      "    self, gradient, retain_graph, create_graph, inputs=inputs\n",
      "  File \"C:\\Users\\20234238\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 199, in backward\n",
      "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2025-06-04 12:48:09,875] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21232\\1854491737.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[0mpruner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_warmup_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpruner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpruner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[0mbest_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    482\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m         )\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             )\n\u001b[0;32m     75\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     ):\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21232\\1854491737.py\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna \n",
    "\n",
    "INPUT_LENGTH = 3600\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using %s' % (device))\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, conv_config, fc_config):\n",
    "        super().__init__()\n",
    "\n",
    "        conv_layers = []\n",
    "        last_out_channels = 1\n",
    "        conv_out_len = INPUT_LENGTH\n",
    "        for config in conv_config:\n",
    "            conv_layers.append(nn.Conv1d(in_channels=last_out_channels, out_channels=config['conv_outchannels'], kernel_size=config['conv_kernelsize']))\n",
    "            conv_layers.append(nn.BatchNorm1d(config[\"conv_outchannels\"]))\n",
    "            conv_layers.append(nn.ReLU())\n",
    "            conv_layers.append(nn.MaxPool1d(2))\n",
    "            last_out_channels = config['conv_outchannels']\n",
    "            conv_out_len = (conv_out_len - (config['conv_kernelsize'] - 1)) // 2\n",
    "        self.conv_stack = nn.Sequential(*conv_layers)\n",
    "\n",
    "        fc_layers = []\n",
    "        last_out = conv_out_len * last_out_channels\n",
    "        fc_layers.append(nn.Flatten())\n",
    "        for config in fc_config:\n",
    "            fc_layers.append(nn.Linear(last_out, config['fc_size']))\n",
    "            fc_layers.append(nn.ReLU())\n",
    "            fc_layers.append(nn.Dropout(config['dropout']))\n",
    "            last_out = config['fc_size']\n",
    "        fc_layers.append(nn.Linear(last_out, num_classes))\n",
    "        self.fc_stack = nn.Sequential(*fc_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.fc_stack(x)\n",
    "        return x\n",
    "    \n",
    "def batch_to_conv_input(batch_input):\n",
    "    return batch_input.unsqueeze(1)\n",
    "\n",
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "\n",
    "    conv_layers = trial.suggest_int('conv_layers', 2, 4)\n",
    "    conv_config = []\n",
    "    for i in range(conv_layers):\n",
    "        conv_config.append({})\n",
    "        conv_config[i]['conv_outchannels'] = trial.suggest_categorical('conv%i_outchannels' % (i), [8, 16, 32, 48, 64])\n",
    "        conv_config[i]['conv_kernelsize'] = trial.suggest_categorical('conv%i_kernelsize' % (i), [5, 7, 9, 11, 13])\n",
    "\n",
    "    fc_layers = trial.suggest_int('fc_layers', 1, 3)\n",
    "    fc_config = []\n",
    "    for i in range(fc_layers):\n",
    "        fc_config.append({})\n",
    "        fc_config[i]['fc_size'] = trial.suggest_categorical('fc%i_size' % (i), [64, 128, 256, 512])\n",
    "        max_dropout = max(0.1, 0.5 - i * 0.2) # Give later layers a lower dropout\n",
    "        fc_config[i]['dropout'] = trial.suggest_float('dropout%i' % (i), 0.0, max_dropout)\n",
    "    \n",
    "    model = NeuralNetwork(\n",
    "        conv_config = conv_config,\n",
    "        fc_config = fc_config\n",
    "    ).to(device)\n",
    "    \n",
    "    # Increasing pos_weight punishes false negatives more heavily\n",
    "    pos_weight = torch.full((num_classes,), 2.0, device=device) \n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, min_lr=1e6)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # For hyperparameter optimization, 10 epochs will be enough to see if the model is good or bad\n",
    "    num_epochs=10\n",
    "    for i in range(num_epochs):\n",
    "        for batch_inputs, batch_labels in train_loader:\n",
    "            # The CNN expects batch_inputs to have a channel dimension (like [batch_size, 1, input_length]), but currently\n",
    "            # batch_input has no channel and the dimensions of batch_inputs are [64, 3600].\n",
    "            # unsqueeze adds a channel dimension in the middle, so batch_input's dimensions become [64, 1, 3600]\n",
    "            batch_inputs = batch_to_conv_input(batch_inputs).to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_inputs)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss)\n",
    "    \n",
    "        results = evaluate(model, test_loader, batch_to_conv_input)\n",
    "        f1 = results['macro']['f1_score']\n",
    "        \n",
    "        # Print some additional metrics at the end of a run\n",
    "        if (i == num_epochs - 1):\n",
    "            for j in range(num_classes):\n",
    "                print('%s, recall: %f, precision: %f' % (label_map[j], results[label_map[j]]['recall'], results[label_map[j]]['precision']))\n",
    "            print('Macro, F1: %f, EMR: %f' % (results['macro']['f1_score'], results['macro']['EMR']))\n",
    "        trial.report(f1, step=i)\n",
    "        \n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return f1\n",
    "    \n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=2)\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "study.optimize(objective, n_trials=25)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "print(best_trial.params)\n",
    "print(best_trial.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17ea47-e088-4f96-9676-723b2fc50253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6e76b-0f0d-44da-8d0e-e4c51216211f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
