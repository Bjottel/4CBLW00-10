{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0468c0dc-59dc-40f5-b36c-60d60235bc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20234238\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "CSV_PATH = 'spectra.csv'\n",
    "\n",
    "# Index -> functional group name\n",
    "label_map = [\n",
    "    'phenol',\n",
    "    'aldehyde',\n",
    "    'arene'\n",
    "]\n",
    "num_classes = len(label_map)\n",
    "\n",
    "# Torch expects every label list to have the same length. Not all samples have the same amount of labels, so instead\n",
    "# we convert the labels to a multi hot vector v, where v_i = 1 if the sample has label i and v_i = 0 otherwise\n",
    "def labels_to_multi_hot_vector(labels):\n",
    "    multi_hot_vector = []\n",
    "    for i in range(len(label_map)):\n",
    "        if label_map[i] in labels:\n",
    "            multi_hot_vector.append(1)\n",
    "        else:\n",
    "            multi_hot_vector.append(0)\n",
    "    return torch.tensor(multi_hot_vector, dtype=torch.float32)\n",
    "\n",
    "class IRDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None, target_transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        # Parse all the json encoded spectra\n",
    "        self.df['spectrum'] = self.df['spectrum'].apply(json.loads)\n",
    "        # Convert the string labels to a multi hot vector\n",
    "        self.df['labels'] = self.df['labels'].apply(labels_to_multi_hot_vector)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        spectrum = self.df['spectrum'].iloc[idx]\n",
    "        # Torch expects spectra as a tensor, not a list\n",
    "        spectrum = torch.tensor(spectrum, dtype=torch.float32)\n",
    "        \n",
    "        labels = self.df['labels'].iloc[idx]\n",
    "        \n",
    "        if (self.transform):\n",
    "            spectrum = self.transform(spectrum)\n",
    "        if (self.target_transform):\n",
    "            labels = self.target_transform(labels)\n",
    "        return spectrum, labels    \n",
    "    \n",
    "dataset = IRDataset(CSV_PATH)\n",
    "\n",
    "# TODO: make this split more fair by ensuring groups are evenly split between train/test\n",
    "# (also add validation set?)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6653ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectra counts per group:\n",
      "phenol: 555\n",
      "aldehyde: 249\n",
      "arene: 5369\n",
      "\n",
      "After Stage 1 → Train: 8577 (≈75.0%), Remainder: 2859 (≈25.0%)\n",
      "After Stage 2 → Test: 1715 (≈15.0%), Validation: 1144 (≈10.0%)\n",
      "\n",
      "Label = phenol\n",
      " Overall prevalence: 4.85%, total: 555\n",
      "→ Train prevalence: 4.85%, total: 416\n",
      "→ Test prevalence: 4.84%, total: 83\n",
      "→ Val prevalence: 4.90%, total: 56\n",
      "\n",
      "Label = aldehyde\n",
      " Overall prevalence: 2.18%, total: 249\n",
      "→ Train prevalence: 2.18%, total: 187\n",
      "→ Test prevalence: 2.16%, total: 37\n",
      "→ Val prevalence: 2.19%, total: 25\n",
      "\n",
      "Label = arene\n",
      " Overall prevalence: 46.95%, total: 5369\n",
      "→ Train prevalence: 46.95%, total: 4027\n",
      "→ Test prevalence: 46.94%, total: 805\n",
      "→ Val prevalence: 46.94%, total: 537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "# 75% train 15% test 10% validation\n",
    "TRAIN_SIZE = 0.75\n",
    "VALIDATION_SIZE = 0.4\n",
    "\n",
    "# Counting how many spectra contain each group (just for logging)\n",
    "counts = {}\n",
    "for i in range(len(label_map)):\n",
    "    counts[label_map[i]] = dataset.df['labels'].apply(lambda L: L[i].item() == 1).sum()\n",
    "print('Spectra counts per group:')\n",
    "for name, cnt in counts.items():\n",
    "    print(f'{name}: {cnt}')\n",
    "\n",
    "try:\n",
    "    # Stage 1 (stratifier): (1 - TRAIN_SIZE)% for “remainder”, TRAIN_SIZE% for training\n",
    "    strat1 = MultilabelStratifiedShuffleSplit(\n",
    "        n_splits=1, \n",
    "        test_size=1 - TRAIN_SIZE,    # (1 - TRAIN_SIZE)% goes to df_remain\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # scikit-learn doesn't work with torch tensors, so we need to convert df['labels'] to a numpy array (messy)\n",
    "    train_idx, remain_idx = next(strat1.split(dataset.df, np.stack(dataset.df['labels'].apply(lambda x: x.numpy()).values)))\n",
    "    df_train = dataset.df.iloc[train_idx].reset_index(drop=True)\n",
    "    Y_train  = dataset.df['labels'][train_idx]\n",
    "    df_remain = dataset.df.iloc[remain_idx].reset_index(drop=True)\n",
    "    Y_remain  = dataset.df['labels'][remain_idx]\n",
    "\n",
    "    print(f\"\\nAfter Stage 1 → Train: {len(df_train)} (≈{TRAIN_SIZE * 100.0}%), Remainder: {len(df_remain)} (≈{(1 - TRAIN_SIZE) * 100.0}%)\")\n",
    "\n",
    "    strat2 = MultilabelStratifiedShuffleSplit(\n",
    "        n_splits=1,\n",
    "        test_size=VALIDATION_SIZE,   # VALIDATION_SIZE% of df_remain → validation\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Same deal as before, Y_remain is a column of tensors, scikit-learn can't work with them\n",
    "    remain_train_idx, remain_test_idx = next(strat2.split(df_remain, np.stack(Y_remain.apply(lambda x: x.numpy()).values)))\n",
    "\n",
    "    # “remain_train_idx” is 75% of df_remain i.e. the test set\n",
    "    df_test  = df_remain.iloc[remain_train_idx].reset_index(drop=True)\n",
    "    # “remain_test_idx” is 25% of df_remain i.e. the validation set\n",
    "    df_val   = df_remain.iloc[remain_test_idx].reset_index(drop=True)\n",
    "\n",
    "    print(f\"After Stage 2 → Test: {len(df_test)} (≈{(1 - TRAIN_SIZE) * (1 - VALIDATION_SIZE) * 100.0}%), Validation: {len(df_val)} (≈{(1 - TRAIN_SIZE) * VALIDATION_SIZE * 100.0}%)\")\n",
    "\n",
    "except ImportError:\n",
    "    # Fallback (non‐stratified) splitting if iterstrat is missing\n",
    "    # Stage 1: TRAIN_SIZE% train, (1 - TRAIN_SIZE)% remainder\n",
    "    df_train, df_remain = train_test_split(\n",
    "        dataset.df, \n",
    "        test_size=1 - TRAIN_SIZE,\n",
    "        random_state=42,\n",
    "        shuffle=True\n",
    "    )\n",
    "    print(f\"\\nAfter Stage 1 (fallback) → Train: {len(df_train)}, Remainder: {len(df_remain)}\")\n",
    "\n",
    "    # Stage 2: within remainder, do (1 - VALIDATION_SIZE)% for test and VALIDATION_SIZE% for val\n",
    "    df_test, df_val = train_test_split(\n",
    "        df_remain,\n",
    "        test_size=VALIDATION_SIZE,   # VALIDATION_SIZE of “remainder” is the validation set \n",
    "        random_state=42,\n",
    "        shuffle=True\n",
    "    )\n",
    "    print(f\"After Stage 2 (fallback) → Test: {len(df_test)}, Validation: {len(df_val)}\")\n",
    "\n",
    "print()\n",
    "for i in range(len(label_map)):\n",
    "    name = label_map[i]\n",
    "    orig_tot = dataset.df['labels'].apply(lambda L: L[i].item() == 1).sum()\n",
    "    train_tot = df_train['labels'].apply(lambda L: L[i].item() == 1).sum()\n",
    "    test_tot  = df_test['labels'].apply(lambda L: L[i].item() == 1).sum()\n",
    "    val_tot   = df_val['labels'].apply(lambda L: L[i].item() == 1).sum()\n",
    "    print(f\"Label = {label_map[i]}\")\n",
    "    print(f\" Overall prevalence: {orig_tot / len(dataset.df):.2%}, total: {orig_tot}\")\n",
    "    print(f\"→ Train prevalence: {train_tot / len(df_train):.2%}, total: {train_tot}\")\n",
    "    print(f\"→ Test prevalence: {test_tot / len(df_test):.2%}, total: {test_tot}\")\n",
    "    print(f\"→ Val prevalence: {val_tot / len(df_val):.2%}, total: {val_tot}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78cf0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(predictions, true_labels, label_index):\n",
    "    true_positive = sum((predictions[i][label_index] == 1).item() and (true_labels[i][label_index] == 1).item() for i in range(len(predictions)))\n",
    "    false_positive = sum((predictions[i][label_index] == 1).item() and (true_labels[i][label_index] == 0).item() for i in range(len(predictions)))\n",
    "    if true_positive == 0:\n",
    "        return 0.0\n",
    "    return true_positive / (true_positive + false_positive)\n",
    "\n",
    "def recall(predictions, true_labels, label_index):\n",
    "    true_positive = sum((predictions[i][label_index] == 1).item() and (true_labels[i][label_index] == 1).item() for i in range(len(predictions)))\n",
    "    false_negative = sum((predictions[i][label_index] == 0).item() and (true_labels[i][label_index] == 1).item() for i in range(len(predictions)))\n",
    "    if true_positive == 0:\n",
    "        return 0.0\n",
    "    return true_positive / (true_positive + false_negative)\n",
    "    \n",
    "def f1_score(predictions, true_labels, label_index):\n",
    "    precision_score = precision(predictions, true_labels, label_index)\n",
    "    recall_score = recall(predictions, true_labels, label_index)\n",
    "    if precision_score == 0 and recall_score == 0:\n",
    "        return 0.0\n",
    "    return 2 * precision_score * recall_score / (precision_score + recall_score)\n",
    "\n",
    "def EMR(predictions, true_labels):\n",
    "    return (predictions == true_labels).all(axis=1).mean()\n",
    "                \n",
    "def evaluate(model, data_loader, batch_transform, device = 'cpu'):\n",
    "    model.eval()\n",
    "    \n",
    "    all_true_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch_inputs, batch_labels in data_loader:\n",
    "            batch_inputs = batch_transform(batch_inputs).to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            outputs = model(batch_inputs)\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predictions = (probabilities > 0.5).float()\n",
    "        \n",
    "            all_true_labels.append(batch_labels)\n",
    "            all_predictions.append(predictions)\n",
    "    \n",
    "    y_true = torch.cat(all_true_labels).cpu().numpy()\n",
    "    y_pred = torch.cat(all_predictions).cpu().numpy()\n",
    "\n",
    "    results = {}\n",
    "    f1_scores = []\n",
    "    for i in range(len(label_map)):\n",
    "        results[label_map[i]] = {}\n",
    "        results[label_map[i]]['precision'] = precision(y_pred, y_true, i)\n",
    "        results[label_map[i]]['recall'] = recall(y_pred, y_true, i)\n",
    "        f1 = f1_score(y_pred, y_true, i)\n",
    "        results[label_map[i]]['f1_score'] = f1\n",
    "        f1_scores.append(f1)\n",
    "    results['macro'] = {}\n",
    "    results['macro']['f1_score'] = np.mean(f1_scores)\n",
    "    results['macro']['EMR'] = EMR(y_pred, y_true)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c43f57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 12:48:57,427] A new study created in memory with name: no-name-387cc3be-9711-43dd-8db8-43961380b166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Using cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 12:53:41,866] Trial 0 finished with value: 0.8044066645949774 and parameters: {'learning_rate': 0.00023893597396861367, 'conv_layers': 2, 'conv0_outchannels': 16, 'conv0_kernelsize': 11, 'conv1_outchannels': 16, 'conv1_kernelsize': 9, 'fc_layers': 3, 'fc0_size': 128, 'dropout0': 0.24303916847160184, 'fc1_size': 128, 'dropout1': 0.09353508310383343, 'fc2_size': 256, 'dropout2': 0.020368387553490564}. Best is trial 0 with value: 0.8044066645949774.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phenol, recall: 0.684685, precision: 0.791667\n",
      "aldehyde, recall: 0.687500, precision: 0.891892\n",
      "arene, recall: 0.931066, precision: 0.875540\n",
      "Macro, F1: 0.804407, EMR: 0.880682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 13:08:26,793] Trial 1 finished with value: 0.8140188439133157 and parameters: {'learning_rate': 0.00021625533428173412, 'conv_layers': 2, 'conv0_outchannels': 48, 'conv0_kernelsize': 9, 'conv1_outchannels': 64, 'conv1_kernelsize': 9, 'fc_layers': 3, 'fc0_size': 64, 'dropout0': 0.4413340799780823, 'fc1_size': 64, 'dropout1': 0.2537198012491565, 'fc2_size': 512, 'dropout2': 0.012078761792962557}. Best is trial 1 with value: 0.8140188439133157.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phenol, recall: 0.711712, precision: 0.790000\n",
      "aldehyde, recall: 0.729167, precision: 0.853659\n",
      "arene, recall: 0.960478, precision: 0.858669\n",
      "Macro, F1: 0.814019, EMR: 0.881119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 13:16:17,694] Trial 2 finished with value: 0.7848253477573904 and parameters: {'learning_rate': 0.007886108483520898, 'conv_layers': 4, 'conv0_outchannels': 8, 'conv0_kernelsize': 11, 'conv1_outchannels': 64, 'conv1_kernelsize': 13, 'conv2_outchannels': 32, 'conv2_kernelsize': 7, 'conv3_outchannels': 16, 'conv3_kernelsize': 7, 'fc_layers': 2, 'fc0_size': 64, 'dropout0': 0.3099955120598508, 'fc1_size': 256, 'dropout1': 0.23612838787078957}. Best is trial 1 with value: 0.8140188439133157.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phenol, recall: 0.648649, precision: 0.692308\n",
      "aldehyde, recall: 0.687500, precision: 0.916667\n",
      "arene, recall: 0.944853, precision: 0.857381\n",
      "Macro, F1: 0.784825, EMR: 0.872378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 13:27:29,548] Trial 3 finished with value: 0.7859436664186005 and parameters: {'learning_rate': 1.2610404115178327e-05, 'conv_layers': 2, 'conv0_outchannels': 48, 'conv0_kernelsize': 11, 'conv1_outchannels': 16, 'conv1_kernelsize': 9, 'fc_layers': 2, 'fc0_size': 512, 'dropout0': 0.18209848841096804, 'fc1_size': 512, 'dropout1': 0.1624020281895291}. Best is trial 1 with value: 0.8140188439133157.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phenol, recall: 0.828829, precision: 0.713178\n",
      "aldehyde, recall: 0.562500, precision: 0.900000\n",
      "arene, recall: 0.939338, precision: 0.861720\n",
      "Macro, F1: 0.785944, EMR: 0.872378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 13:33:20,214] Trial 4 finished with value: 0.8074544461802012 and parameters: {'learning_rate': 0.00016232356173120818, 'conv_layers': 4, 'conv0_outchannels': 16, 'conv0_kernelsize': 9, 'conv1_outchannels': 16, 'conv1_kernelsize': 7, 'conv2_outchannels': 32, 'conv2_kernelsize': 9, 'conv3_outchannels': 8, 'conv3_kernelsize': 9, 'fc_layers': 1, 'fc0_size': 64, 'dropout0': 0.14069673745657274}. Best is trial 1 with value: 0.8140188439133157.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phenol, recall: 0.855856, precision: 0.650685\n",
      "aldehyde, recall: 0.666667, precision: 0.914286\n",
      "arene, recall: 0.976103, precision: 0.855761\n",
      "Macro, F1: 0.807454, EMR: 0.882867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 13:35:46,030] Trial 5 pruned. \n",
      "[I 2025-06-04 13:45:09,452] Trial 6 finished with value: 0.8245929753783158 and parameters: {'learning_rate': 0.000759940947059361, 'conv_layers': 4, 'conv0_outchannels': 8, 'conv0_kernelsize': 11, 'conv1_outchannels': 48, 'conv1_kernelsize': 7, 'conv2_outchannels': 64, 'conv2_kernelsize': 9, 'conv3_outchannels': 8, 'conv3_kernelsize': 5, 'fc_layers': 2, 'fc0_size': 512, 'dropout0': 0.03653465374241188, 'fc1_size': 64, 'dropout1': 0.028391032162909013}. Best is trial 6 with value: 0.8245929753783158.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phenol, recall: 0.702703, precision: 0.787879\n",
      "aldehyde, recall: 0.750000, precision: 0.900000\n",
      "arene, recall: 0.961397, precision: 0.868771\n",
      "Macro, F1: 0.824593, EMR: 0.889860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-04 13:46:33,460] Trial 7 pruned. \n",
      "[I 2025-06-04 13:49:12,226] Trial 8 pruned. \n",
      "[I 2025-06-04 14:55:41,909] Trial 9 finished with value: 0.833229528814681 and parameters: {'learning_rate': 5.1457655488275636e-05, 'conv_layers': 4, 'conv0_outchannels': 16, 'conv0_kernelsize': 7, 'conv1_outchannels': 48, 'conv1_kernelsize': 5, 'conv2_outchannels': 16, 'conv2_kernelsize': 11, 'conv3_outchannels': 32, 'conv3_kernelsize': 9, 'fc_layers': 1, 'fc0_size': 512, 'dropout0': 0.10207644405034622}. Best is trial 9 with value: 0.833229528814681.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phenol, recall: 0.756757, precision: 0.831683\n",
      "aldehyde, recall: 0.666667, precision: 0.969697\n",
      "arene, recall: 0.945772, precision: 0.890138\n",
      "Macro, F1: 0.833230, EMR: 0.897290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-06-04 15:02:15,768] Trial 10 failed with parameters: {'learning_rate': 0.001011707732783943, 'conv_layers': 4, 'conv0_outchannels': 64, 'conv0_kernelsize': 7, 'conv1_outchannels': 48, 'conv1_kernelsize': 5, 'conv2_outchannels': 16, 'conv2_kernelsize': 13, 'conv3_outchannels': 32, 'conv3_kernelsize': 11, 'fc_layers': 1, 'fc0_size': 512, 'dropout0': 0.2697687452412213} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\20234238\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\20234238\\AppData\\Local\\Temp\\ipykernel_21232\\1854491737.py\", line 91, in objective\n",
      "    results = evaluate(model, test_loader, batch_to_conv_input)\n",
      "  File \"C:\\Users\\20234238\\AppData\\Local\\Temp\\ipykernel_21232\\1620697563.py\", line 34, in evaluate\n",
      "    outputs = model(batch_inputs)\n",
      "  File \"C:\\Users\\20234238\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\20234238\\AppData\\Local\\Temp\\ipykernel_21232\\1854491737.py\", line 36, in forward\n",
      "    x = self.conv_stack(x)\n",
      "  File \"C:\\Users\\20234238\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\20234238\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 204, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\20234238\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\20234238\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 313, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"C:\\Users\\20234238\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 310, in _conv_forward\n",
      "    self.padding, self.dilation, self.groups)\n",
      "KeyboardInterrupt\n",
      "[W 2025-06-04 15:02:15,905] Trial 10 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21232\\1854491737.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[0mpruner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_warmup_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpruner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpruner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[0mbest_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    482\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m         )\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             )\n\u001b[0;32m     75\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     ):\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21232\\1854491737.py\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_to_conv_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'f1_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21232\\1620697563.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, data_loader, batch_transform, device)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mbatch_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mbatch_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[0mprobabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprobabilities\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21232\\1854491737.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    308\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m    309\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[1;32m--> 310\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna \n",
    "\n",
    "INPUT_LENGTH = 3600\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using %s' % (device))\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, conv_config, fc_config):\n",
    "        super().__init__()\n",
    "\n",
    "        conv_layers = []\n",
    "        last_out_channels = 1\n",
    "        conv_out_len = INPUT_LENGTH\n",
    "        for config in conv_config:\n",
    "            conv_layers.append(nn.Conv1d(in_channels=last_out_channels, out_channels=config['conv_outchannels'], kernel_size=config['conv_kernelsize']))\n",
    "            conv_layers.append(nn.BatchNorm1d(config[\"conv_outchannels\"]))\n",
    "            conv_layers.append(nn.ReLU())\n",
    "            conv_layers.append(nn.MaxPool1d(2))\n",
    "            last_out_channels = config['conv_outchannels']\n",
    "            conv_out_len = (conv_out_len - (config['conv_kernelsize'] - 1)) // 2\n",
    "        self.conv_stack = nn.Sequential(*conv_layers)\n",
    "\n",
    "        fc_layers = []\n",
    "        last_out = conv_out_len * last_out_channels\n",
    "        fc_layers.append(nn.Flatten())\n",
    "        for config in fc_config:\n",
    "            fc_layers.append(nn.Linear(last_out, config['fc_size']))\n",
    "            fc_layers.append(nn.ReLU())\n",
    "            fc_layers.append(nn.Dropout(config['dropout']))\n",
    "            last_out = config['fc_size']\n",
    "        fc_layers.append(nn.Linear(last_out, num_classes))\n",
    "        self.fc_stack = nn.Sequential(*fc_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.fc_stack(x)\n",
    "        return x\n",
    "    \n",
    "def batch_to_conv_input(batch_input):\n",
    "    return batch_input.unsqueeze(1)\n",
    "\n",
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "\n",
    "    conv_layers = trial.suggest_int('conv_layers', 2, 4)\n",
    "    conv_config = []\n",
    "    for i in range(conv_layers):\n",
    "        conv_config.append({})\n",
    "        conv_config[i]['conv_outchannels'] = trial.suggest_categorical('conv%i_outchannels' % (i), [8, 16, 32, 48, 64])\n",
    "        conv_config[i]['conv_kernelsize'] = trial.suggest_categorical('conv%i_kernelsize' % (i), [5, 7, 9, 11, 13])\n",
    "\n",
    "    fc_layers = trial.suggest_int('fc_layers', 1, 3)\n",
    "    fc_config = []\n",
    "    for i in range(fc_layers):\n",
    "        fc_config.append({})\n",
    "        fc_config[i]['fc_size'] = trial.suggest_categorical('fc%i_size' % (i), [64, 128, 256, 512])\n",
    "        max_dropout = max(0.1, 0.5 - i * 0.2) # Give later layers a lower dropout\n",
    "        fc_config[i]['dropout'] = trial.suggest_float('dropout%i' % (i), 0.0, max_dropout)\n",
    "    \n",
    "    model = NeuralNetwork(\n",
    "        conv_config = conv_config,\n",
    "        fc_config = fc_config\n",
    "    ).to(device)\n",
    "    \n",
    "    # Increasing pos_weight punishes false negatives more heavily\n",
    "    pos_weight = torch.full((num_classes,), 2.0, device=device) \n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, min_lr=1e6)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # For hyperparameter optimization, 10 epochs will be enough to see if the model is good or bad\n",
    "    num_epochs=10\n",
    "    for i in range(num_epochs):\n",
    "        for batch_inputs, batch_labels in train_loader:\n",
    "            # The CNN expects batch_inputs to have a channel dimension (like [batch_size, 1, input_length]), but currently\n",
    "            # batch_input has no channel and the dimensions of batch_inputs are [64, 3600].\n",
    "            # unsqueeze adds a channel dimension in the middle, so batch_input's dimensions become [64, 1, 3600]\n",
    "            batch_inputs = batch_to_conv_input(batch_inputs).to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_inputs)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss)\n",
    "    \n",
    "        results = evaluate(model, test_loader, batch_to_conv_input)\n",
    "        f1 = results['macro']['f1_score']\n",
    "        \n",
    "        # Print some additional metrics at the end of a run\n",
    "        if (i == num_epochs - 1):\n",
    "            for j in range(num_classes):\n",
    "                print('%s, recall: %f, precision: %f' % (label_map[j], results[label_map[j]]['recall'], results[label_map[j]]['precision']))\n",
    "            print('Macro, F1: %f, EMR: %f' % (results['macro']['f1_score'], results['macro']['EMR']))\n",
    "        trial.report(f1, step=i)\n",
    "        \n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return f1\n",
    "    \n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=2)\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "study.optimize(objective, n_trials=25)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "print(best_trial.params)\n",
    "print(best_trial.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17ea47-e088-4f96-9676-723b2fc50253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6e76b-0f0d-44da-8d0e-e4c51216211f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
