{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0468c0dc-59dc-40f5-b36c-60d60235bc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20234238\\AppData\\Local\\anaconda3\\envs\\cbl_ir\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "INPUT_LENGTH = 3600\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using %s' % (device))\n",
    "\n",
    "TRAIN_PATH_CLEAN = 'spectra_train_clean.csv'\n",
    "TEST_PATH = 'spectra_test.csv'\n",
    "VALIDATION_PATH = 'spectra_validation.csv'\n",
    "\n",
    "# Index -> functional group name\n",
    "label_map = [\n",
    "    'phenol',\n",
    "    'aldehyde',\n",
    "    'arene'\n",
    "]\n",
    "num_classes = len(label_map)\n",
    "\n",
    "class IRDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None, target_transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        # Parse all the json encoded spectra\n",
    "        self.df['spectrum'] = self.df['spectrum'].apply(json.loads)\n",
    "        self.df['labels'] = self.df['labels'].apply(json.loads)\n",
    "        self.df['labels'] = self.df['labels'].apply(lambda L: torch.tensor(L, dtype=torch.float32))\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        spectrum = self.df['spectrum'].iloc[idx]\n",
    "        # Torch expects spectra as a tensor, not a list\n",
    "        spectrum = torch.tensor(spectrum, dtype=torch.float32)\n",
    "        \n",
    "        labels = self.df['labels'].iloc[idx]\n",
    "        \n",
    "        if (self.transform):\n",
    "            spectrum = self.transform(spectrum)\n",
    "        if (self.target_transform):\n",
    "            labels = self.target_transform(labels)\n",
    "        return spectrum, labels \n",
    "    \n",
    "def get_pos_weights(dataset):\n",
    "    weights = []\n",
    "    total = len(dataset.df)\n",
    "    for i in range(len(label_map)):\n",
    "        number_of_label = dataset.df['labels'].apply(lambda L: bool(L[i] == 1)).sum()\n",
    "        weights.append((total - number_of_label) / number_of_label)\n",
    "    weights = torch.tensor(weights, dtype=torch.float32)\n",
    "    return weights\n",
    "    \n",
    "test_set = IRDataset(TEST_PATH)\n",
    "test_loader = DataLoader(test_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78cf0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(predictions, true_labels, label_index):\n",
    "    true_positive = sum((predictions[i][label_index] == 1).item() and (true_labels[i][label_index] == 1).item() for i in range(len(predictions)))\n",
    "    false_positive = sum((predictions[i][label_index] == 1).item() and (true_labels[i][label_index] == 0).item() for i in range(len(predictions)))\n",
    "    if true_positive == 0:\n",
    "        return 0.0\n",
    "    return true_positive / (true_positive + false_positive)\n",
    "\n",
    "def recall(predictions, true_labels, label_index):\n",
    "    true_positive = sum((predictions[i][label_index] == 1).item() and (true_labels[i][label_index] == 1).item() for i in range(len(predictions)))\n",
    "    false_negative = sum((predictions[i][label_index] == 0).item() and (true_labels[i][label_index] == 1).item() for i in range(len(predictions)))\n",
    "    if true_positive == 0:\n",
    "        return 0.0\n",
    "    return true_positive / (true_positive + false_negative)\n",
    "    \n",
    "def f1_score(predictions, true_labels, label_index):\n",
    "    precision_score = precision(predictions, true_labels, label_index)\n",
    "    recall_score = recall(predictions, true_labels, label_index)\n",
    "    if precision_score == 0 and recall_score == 0:\n",
    "        return 0.0\n",
    "    return 2 * precision_score * recall_score / (precision_score + recall_score)\n",
    "\n",
    "def EMR(predictions, true_labels):\n",
    "    return (predictions == true_labels).all(axis=1).mean()\n",
    "\n",
    "\n",
    "def batch_to_conv_input(batch_input):\n",
    "    # The CNN expects batch_inputs to have a channel dimension (like [batch_size, 1, input_length]), but currently\n",
    "    # batch_input has no channel and the dimensions of batch_inputs are [64, 3600].\n",
    "    # unsqueeze adds a channel dimension in the middle, so batch_input's dimensions become [64, 1, 3600]\n",
    "    return batch_input.unsqueeze(1)\n",
    "\n",
    "# Trains the model for one epoch\n",
    "def train_epoch(model, dataloader, optimizer, criterion, scheduler, device='cpu'):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_inputs, batch_labels in dataloader:\n",
    "            batch_inputs = batch_to_conv_input(batch_inputs).to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_inputs)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "# Evaluates the model, returning various metrics like F1/EMR/precision/recall for every class\n",
    "def evaluate(model, data_loader, device='cpu'):\n",
    "    model.eval()\n",
    "    \n",
    "    all_true_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch_inputs, batch_labels in data_loader:\n",
    "            batch_inputs = batch_to_conv_input(batch_inputs).to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            outputs = model(batch_inputs)\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predictions = (probabilities > 0.5).float()\n",
    "        \n",
    "            all_true_labels.append(batch_labels)\n",
    "            all_predictions.append(predictions)\n",
    "    \n",
    "    y_true = torch.cat(all_true_labels).cpu().numpy()\n",
    "    y_pred = torch.cat(all_predictions).cpu().numpy()\n",
    "\n",
    "    results = {}\n",
    "    f1_scores = []\n",
    "    for i in range(len(label_map)):\n",
    "        results[label_map[i]] = {}\n",
    "        results[label_map[i]]['precision'] = precision(y_pred, y_true, i)\n",
    "        results[label_map[i]]['recall'] = recall(y_pred, y_true, i)\n",
    "        f1 = f1_score(y_pred, y_true, i)\n",
    "        results[label_map[i]]['f1_score'] = f1\n",
    "        f1_scores.append(f1)\n",
    "    results['macro'] = {}\n",
    "    results['macro']['f1_score'] = np.mean(f1_scores)\n",
    "    results['macro']['EMR'] = EMR(y_pred, y_true)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c43f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna \n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, conv_config, fc_config, activation):\n",
    "        super().__init__()\n",
    "        \n",
    "        activation_func = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(),\n",
    "            'gelu': nn.GELU(),\n",
    "        }[activation]\n",
    "        \n",
    "\n",
    "        conv_layers = []\n",
    "        last_out_channels = 1\n",
    "        conv_out_len = INPUT_LENGTH\n",
    "        for config in conv_config:\n",
    "            conv_layers.append(nn.Conv1d(in_channels=last_out_channels, out_channels=config['conv_outchannels'], kernel_size=config['conv_kernelsize']))\n",
    "            conv_layers.append(nn.BatchNorm1d(config[\"conv_outchannels\"]))\n",
    "            conv_layers.append(activation_func)\n",
    "            \n",
    "            if (config['pooling'] == 'max'):\n",
    "                conv_layers.append(nn.MaxPool1d(config['pooling_kernelsize']))\n",
    "            elif (config['pooling'] == 'avg'):\n",
    "                conv_layers.append(nn.AvgPool1d(config['pooling_kernelsize']))\n",
    "            last_out_channels = config['conv_outchannels']\n",
    "            conv_out_len = (conv_out_len - (config['conv_kernelsize'] - 1)) // config['pooling_kernelsize']\n",
    "            \n",
    "            # If the kernel sizes get a bit too big the one of the dimensions of the out-tensor can become 0 (or even negative)\n",
    "            # This is invalid so we just return an error if this happens and try again with a different configuration\n",
    "            if conv_out_len <= 0:\n",
    "                raise ValueError(f\"Output length became zero or negative after layer with config: {config}\")\n",
    "        self.conv_stack = nn.Sequential(*conv_layers)\n",
    "\n",
    "        fc_layers = []\n",
    "        last_out = conv_out_len * last_out_channels\n",
    "        \n",
    "        if last_out <= 0:\n",
    "            raise ValueError(f\"Output length became zero or negative\")\n",
    "            \n",
    "        fc_layers.append(nn.Flatten())\n",
    "        for config in fc_config:\n",
    "            fc_layers.append(nn.Linear(last_out, config['fc_size']))\n",
    "            fc_layers.append(activation_func)\n",
    "            fc_layers.append(nn.Dropout(config['dropout']))\n",
    "            last_out = config['fc_size']\n",
    "        fc_layers.append(nn.Linear(last_out, num_classes))\n",
    "        self.fc_stack = nn.Sequential(*fc_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.fc_stack(x)\n",
    "        return x\n",
    "\n",
    "# Converts the hyperparameters given by optuna to a valid neural network (if possible)\n",
    "def optuna_trial_to_model(trial, pos_weights):\n",
    "    conv_config = []\n",
    "    for i in range(trial['conv_layers']):\n",
    "        conv_config.append({})\n",
    "        conv_config[i]['conv_outchannels'] = trial['conv%i_outchannels' % (i)]\n",
    "        conv_config[i]['conv_kernelsize'] = trial['conv%i_kernelsize' % (i)]\n",
    "        conv_config[i]['pooling'] = trial['conv%i_pooling' % (i)]\n",
    "        conv_config[i]['pooling_kernelsize'] = trial['conv%i_pooling_kernelsize' % (i)]\n",
    "        \n",
    "    fc_config = []\n",
    "    for i in range(trial['fc_layers']):\n",
    "        fc_config.append({})\n",
    "        fc_config[i]['fc_size'] = trial['fc%i_size' % (i)]\n",
    "        fc_config[i]['dropout'] = trial['dropout%i' % (i)]\n",
    "        \n",
    "    model = NeuralNetwork(\n",
    "        conv_config = conv_config,\n",
    "        fc_config = fc_config,\n",
    "        activation = trial['activation']\n",
    "    ).to(device)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=trial['learning_rate'], weight_decay=trial['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, min_lr=1e-7)\n",
    "    \n",
    "    return model, criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17ea47-e088-4f96-9676-723b2fc50253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# After 100 trials of tuning the hyperparameters of the model using the unaltered training set, Optuna found these\n",
    "# hyperparameters that performed the best: \n",
    "hyp_best_clean = {'learning_rate': 0.0007618554013184676, 'weight_decay': 4.758290105243128e-05, 'activation': 'gelu', 'conv_layers': 4, 'conv0_outchannels': 32, 'conv0_kernelsize': 11, 'conv1_outchannels': 16, 'conv1_kernelsize': 11, 'conv2_outchannels': 64, 'conv2_kernelsize': 5, 'conv3_outchannels': 64, 'conv3_kernelsize': 9, 'fc_layers': 1, 'fc0_size': 256, 'dropout0': 0.3526655406895286}\n",
    "\n",
    "TRAIN_PATH_SMOTE = 'spectra_train_SMOTE.csv'\n",
    "TRAIN_PATH_AUG = 'spectra_train_rand_aug.csv'\n",
    "TRAIN_PATH_AUG_SMOTE = 'spectra_train_rand_aug_smote.csv'\n",
    "TRAIN_PATH_AUG_OVERSAMPLED = 'spectra_train_rand_aug_oversampled.csv'\n",
    "\n",
    "def test_dataset(data_path):\n",
    "    # When training the models, random number generation is involved.\n",
    "    # This may lead to unfair comparisons as some models get lucky and others get unlucky, so we just use the same random seed\n",
    "    # for every model to eliminate this luck.\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)  \n",
    "    torch.cuda.manual_seed_all(42)     \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    dataset = IRDataset(data_path)\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    best_model, criterion, optimizer, scheduler = optuna_trial_to_model(hyp_best_clean)\n",
    "    # Training the model on 25 epochs should be enough to get a good idea of how\n",
    "    # an augmentation affects the model's performance\n",
    "    train(best_model, loader, 25, optimizer, criterion, scheduler)\n",
    "    \n",
    "    results = evaluate(best_model, test_loader, device=device)\n",
    "    \n",
    "    print('Finished evaluating model, results:')\n",
    "    print(results)\n",
    "   \n",
    "# Since most of the training sets are very large we can only test them one at a time or we risk running out of memory\n",
    "data_path = TRAIN_PATH_AUG_OVERSAMPLED\n",
    "#test_dataset(data_path)\n",
    "\n",
    "\n",
    "# After trying all the datasets, the oversampled augmented dataset performed the best so we will be using it for the final model\n",
    "dataset = IRDataset(TRAIN_PATH_AUG_OVERSAMPLED)\n",
    "train_set = dataset\n",
    "\n",
    "# Add custom pos_weights to punish false negatives for minority classes more heavily\n",
    "# This balances precision/recall more, as when using default pos_weights ([0, 0, 0]) minority classes tend to have high precision but low recall\n",
    "# We take the square root of these weights since the normal weights were a little too agressive \n",
    "pos_weights = torch.sqrt(get_pos_weights(dataset)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b80c31",
   "metadata": {},
   "source": [
    "The code above was run for every dataset made in Augmentations.ipynb (unaltered, SMOTE, augmented).\n",
    "The results were consistent across several trials, the results described here are the results of the first run.\n",
    "\n",
    "Results for the code above:\n",
    "\n",
    "For the unaltered dataset, the results were as follows: \n",
    "{'phenol': {'precision': 0.8875, 'recall': 0.6635514018691588, 'f1_score': 0.7593582887700534}, \n",
    " 'aldehyde': {'precision': 0.8928571428571429, 'recall': 0.746268656716418, 'f1_score': 0.8130081300813009}, \n",
    "  'arene': {'precision': 0.9289267945984364, 'recall': 0.9624447717231223, 'f1_score': 0.9453887884267631}, \n",
    "  'macro': {'f1_score': 0.8392517357593725, 'EMR': 0.9107600341588385}}\n",
    "  \n",
    "This is a base measure. Recall and precision for arenes are fine, but especially recall could definetly be improved for \n",
    "phenols/aldehydes. \n",
    "\n",
    "\n",
    "After applying SMOTE to the unaltered dataset such that all classes were equally represented, the results were:\n",
    "{'phenol': {'precision': 0.7878787878787878, 'recall': 0.7289719626168224, 'f1_score': 0.7572815533980582}, \n",
    " 'aldehyde': {'precision': 0.9230769230769231, 'recall': 0.7164179104477612, 'f1_score': 0.8067226890756303}, \n",
    " 'arene': {'precision': 0.924274593064402, 'recall': 0.9617083946980854, 'f1_score': 0.942619992782389}, \n",
    " 'macro': {'f1_score': 0.8355414117520258, 'EMR': 0.9064901793339026}}\n",
    " \n",
    "This model performs slightly worse on the dataset with SMOTE. Most likely this is due to the model slightly overfitting\n",
    "because most of the samples generated by SMOTE come from only a few original samples. Alternatively SMOTE may just not be fitted for IR spectra because linearly interpolating between two spectra may result in an unrealistic/nonsensical spectrum. Because SMOTE generates very large datasets without really improving performance we won't be using it in our final model.\n",
    "\n",
    "\n",
    "After applying the augmentations to the unaltered dataset, the results were:\n",
    "{'phenol': {'precision': 0.8681318681318682, 'recall': 0.7383177570093458, 'f1_score': 0.797979797979798}, \n",
    " 'aldehyde': {'precision': 0.9803921568627451, 'recall': 0.746268656716418, 'f1_score': 0.847457627118644}, \n",
    "  'arene': {'precision': 0.9131944444444444, 'recall': 0.9683357879234168, 'f1_score': 0.9399571122230165}, \n",
    "  'macro': {'f1_score': 0.8617981791071528, 'EMR': 0.9060631938514091}}\n",
    "  \n",
    "This is an improvement over the unaltered model, with precision and recall generally improving.\n",
    "This may be because the model is able to generalize the data better since we are making it more robust by intentionally \\\n",
    "adding noise to our data. Additionally, by applying these augmentations we are generating more samples for minority classes like phenols and aldehydes, which may improve their performance. The only downside of this technique is that the generated is really large (5 times the size of the original dataset). This makes training take very long and if we are not careful Python will run out of RAM because it has to load a 5GB training set into memory. If this happens we have to do the training all over again which is far from ideal.\n",
    "\n",
    "\n",
    "After applying the augmentations to the unaltered dataset and basing the number of augmentations on the rarity of a label,\n",
    "the results were:\n",
    "{'phenol': {'precision': 0.8863636363636364, 'recall': 0.7289719626168224, 'f1_score': 0.8}, \n",
    " 'aldehyde': {'precision': 0.9454545454545454, 'recall': 0.7761194029850746, 'f1_score': 0.8524590163934428}, \n",
    " 'arene': {'precision': 0.8975741239892183, 'recall': 0.9808541973490427, 'f1_score': 0.9373680506685433}, \n",
    " 'macro': {'f1_score': 0.8632756890206621, 'EMR': 0.9026473099914603}}\n",
    "\n",
    "In the above example, more augmentations were generated for rarer labels (phenols and aldehydes) and fewer were generated for more common labels (arenes). This was done in an attempt to combat class imbalance. In the trial above, 8 augmentations were generated for phenols, 10 were generated for aldehydes and 2 were generated for arenes. Other numbers were tried (such as 10 for phenols, 15 for aldehydes, 1 for arenes), but this was the best performing configuration.\n",
    "This model shows a slight improvement over the previous one, though the performance gain is almost negligible.\n",
    "Training this model is a lot faster however, since augmenting the training set this way results in a far smaller training set (33539 samples as opposed to 70266). For this reason we chose this augmentation technique for our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6e76b-0f0d-44da-8d0e-e4c51216211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The objective function for hyperparameter optimizartion\n",
    "def objective(trial):\n",
    "    # Not every combination of hyperparameters may be valid\n",
    "    # If an invalid combination occur we will get an exception when trying to build the model\n",
    "    # If this exception is thrown we just try again with new hyperparameters\n",
    "    while True:\n",
    "        try:\n",
    "            # Suggest hyperparameters for the current trial\n",
    "            learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "            weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "            activation = trial.suggest_categorical('activation', ['relu', 'leaky_relu', 'gelu'])\n",
    "\n",
    "            conv_layers = trial.suggest_int('conv_layers', 2, 5)\n",
    "            conv_config = []\n",
    "            for i in range(conv_layers):\n",
    "                conv_config.append({})\n",
    "        \n",
    "                # Make the number of outchannels for early layers smaller to prevent early overfitting\n",
    "                if i == 0:\n",
    "                    outchannels_choices = [16, 32]\n",
    "                elif i == 1:\n",
    "                    outchannels_choices = [32, 64]\n",
    "                else:\n",
    "                    outchannels_choices = [64, 128]\n",
    "                conv_config[i]['conv_outchannels'] = trial.suggest_categorical('conv%i_outchannels' % (i), outchannels_choices)\n",
    "                conv_config[i]['conv_kernelsize'] = trial.suggest_categorical('conv%i_kernelsize' % (i), [3, 5, 7, 9, 11])\n",
    "                conv_config[i]['pooling'] = trial.suggest_categorical(f'conv{i}_pooling', ['max', 'avg'])\n",
    "                conv_config[i]['pooling_kernelsize'] = trial.suggest_categorical(f'conv{i}_pooling_kernelsize', [2, 4, 8])\n",
    "\n",
    "            fc_layers = trial.suggest_int('fc_layers', 1, 3)\n",
    "            fc_config = []\n",
    "            for i in range(fc_layers):\n",
    "                fc_config.append({})\n",
    "                fc_config[i]['fc_size'] = trial.suggest_categorical('fc%i_size' % (i), [64, 128, 256, 512])\n",
    "                max_dropout = max(0.1, 0.5 - i * 0.1) # Give later layers a lower dropout\n",
    "                fc_config[i]['dropout'] = trial.suggest_float('dropout%i' % (i), 0.0, max_dropout)\n",
    "        \n",
    "            batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "            train_set_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "            # Build a model with the chosen hyperparameters\n",
    "            model = NeuralNetwork(\n",
    "                conv_config = conv_config,\n",
    "                fc_config = fc_config,\n",
    "                activation = activation\n",
    "            ).to(device)\n",
    "            \n",
    "            break\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            # If some combination of hyperparameters results in an invalid model we can simply prune the current trial\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "            continue\n",
    "        \n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, min_lr=1e6)\n",
    "    \n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)  \n",
    "    torch.cuda.manual_seed_all(42)     \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    # For hyperparameter optimization, 15 epochs will be enough to see if the model is good or bad\n",
    "    num_epochs = 10\n",
    "    for i in range(num_epochs):\n",
    "        train_epoch(model, train_set_loader, optimizer, criterion, scheduler)\n",
    "    \n",
    "        results = evaluate(model, test_loader, device=device)\n",
    "        \n",
    "        if (i == num_epochs - 1):\n",
    "            for j in range(num_classes):\n",
    "                print('%s, recall: %f, precision: %f' % (label_map[j], results[label_map[j]]['recall'], results[label_map[j]]['precision']))\n",
    "            print('Macro, F1: %f, EMR: %f' % (results['macro']['f1_score'], results['macro']['EMR']))\n",
    "            \n",
    "        f1 = results['macro']['f1_score']\n",
    "        scheduler.step(f1)\n",
    "        \n",
    "        # Print some additional metrics at the end of a run\n",
    "        trial.report(f1, step=i)\n",
    "        \n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return f1\n",
    "    \n",
    "def hyp_optimization(objective, n_trials)\n",
    "    # Use a pruner to stop bad trials early\n",
    "    pruner = optuna.pruners.MedianPruner(n_warmup_steps=3)\n",
    "    study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "    study.optimize(objective=objective, n_trials=n_trials)\n",
    "\n",
    "    best_trial = study.best_trial\n",
    "    print(best_trial.params)\n",
    "    print(best_trial.value)\n",
    "    \n",
    "    return best_trial\n",
    "\n",
    "#best_hyp = hyp_optimization(objective, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0e4a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# These hyperparameters performed best for the augmented dataset\n",
    "hyp_best_aug = {'learning_rate': 0.0005284129498503046, 'weight_decay': 3.392926768530441e-06, 'activation': 'relu', 'conv_layers': 3, 'conv0_outchannels': 32, 'conv0_kernelsize': 11, 'conv0_pooling': 'max', 'conv0_pooling_kernelsize': 8, 'conv1_outchannels': 32, 'conv1_kernelsize': 11, 'conv1_pooling': 'max', 'conv1_pooling_kernelsize': 2, 'conv2_outchannels': 128, 'conv2_kernelsize': 7, 'conv2_pooling': 'max', 'conv2_pooling_kernelsize': 2, 'fc_layers': 2, 'fc0_size': 256, 'dropout0': 0.13838847644999705, 'fc1_size': 512, 'dropout1': 0.32601262149977256, 'batch_size': 32}\n",
    "\n",
    "best_model, criterion, optimizer, scheduler = optuna_trial_to_model(hyp_best_aug, pos_weights)\n",
    "train_set_loader = DataLoader(train_set, batch_size=hyp_best_aug['batch_size'], shuffle=True)\n",
    "\n",
    "best_f1 = 0\n",
    "best_model_state = None\n",
    "wait = 0\n",
    "patience = 10\n",
    "f1_scores = [0]\n",
    "lrs = [hyp_best_aug['learning_rate']]\n",
    "\n",
    "{'learning_rate': 0.0005284129498503046, 'weight_decay': 3.392926768530441e-06, 'activation': 'relu', \n",
    " 'conv_layers': 3, \n",
    " 'conv0_outchannels': 32, 'conv0_kernelsize': 11, 'conv0_pooling': 'max', 'conv0_pooling_kernelsize': 8, \n",
    " 'conv1_outchannels': 32, 'conv1_kernelsize': 11, 'conv1_pooling': 'max', 'conv1_pooling_kernelsize': 2, \n",
    " 'conv2_outchannels': 128, 'conv2_kernelsize': 7, 'conv2_pooling': 'max', 'conv2_pooling_kernelsize': 2, \n",
    " 'fc_layers': 2, 'fc0_size': 256, 'dropout0': 0.13838847644999705, \n",
    " 'fc1_size': 512, 'dropout1': 0.32601262149977256, 'batch_size': 32}\n",
    "\n",
    "\n",
    "epochs_for_full_train = 100\n",
    "for i in range(epochs_for_full_train):\n",
    "    train_epoch(best_model, train_set_loader, optimizer, criterion, scheduler)\n",
    "    \n",
    "    results = evaluate(best_model, test_loader, device=device)\n",
    "    \n",
    "    f1 = results['macro']['f1_score']\n",
    "    f1_scores.append(f1)\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    lrs.append(lr)\n",
    "    scheduler.step(f1)\n",
    "    \n",
    "    print('Epoch %i: F1 = %f, LR = %f' % (i, f1, lr))\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model_state = best_model.state_dict()\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print('Early stopping triggered at epoch %i. Best F1: %f' % (i, best_f1))\n",
    "            break\n",
    "\n",
    "if best_model_state is not None:\n",
    "    # Save the final model's parameters so we can easily use it later\n",
    "    torch.save(best_model_state, 'final_model.pth')\n",
    "    print('Saved best model')\n",
    "    \n",
    "    # For some reason the kernel keeps dying when trying to make the graphs so we just save the data and make the graphs later\n",
    "    np.save('f1_scores_best_model', np.array(f1_scores))\n",
    "    np.save('lr_best_model', np.array(lrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf5421",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(f1_scores, label='Macro F1')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Macro F1 Over Time')\n",
    "plt.legend()\n",
    "plt.savefig('f1.png')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(lrs, label='Learning Rate', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.legend()\n",
    "plt.savefig('lr_curve.png')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35160e91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
